from typing import List, Dict, Any
from pydantic import BaseModel, Field
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from src.agents.need_finder import NeedItem

# å®šç¾©è©•ä¼°çµæœçµæ§‹
class NeedEvaluation(BaseModel):
    need_title: str = Field(description="è¢«è©•ä¼°çš„éœ€æ±‚æ¨™é¡Œ")
    feasibility_score: float = Field(description="å¯è¡Œæ€§åˆ†æ•¸ (0-10)", ge=0, le=10)
    impact_score: float = Field(description="å½±éŸ¿åŠ›åˆ†æ•¸ (0-10)", ge=0, le=10)
    innovation_score: float = Field(description="å‰µæ–°æ€§åˆ†æ•¸ (0-10)", ge=0, le=10)
    resource_score: float = Field(description="è³‡æºéœ€æ±‚åˆ†æ•¸ (0-10ï¼Œ10è¡¨ç¤ºè³‡æºéœ€æ±‚ä½)", ge=0, le=10)
    overall_score: float = Field(description="ç¸½é«”åˆ†æ•¸ (0-10)", ge=0, le=10)
    strengths: List[str] = Field(description="å„ªå‹¢æ¸…å–®")
    weaknesses: List[str] = Field(description="åŠ£å‹¢æ¸…å–®")
    recommendations: List[str] = Field(description="æ”¹é€²å»ºè­°æ¸…å–®")

# å®šç¾©æ•´é«”è©•ä¼°è¼¸å‡ºçµæ§‹
class NeedsEvaluationOutput(BaseModel):
    evaluations: List[NeedEvaluation] = Field(description="æ‰€æœ‰éœ€æ±‚çš„è©•ä¼°çµæœ")
    summary: str = Field(description="æ•´é«”è©•ä¼°ç¸½çµ")
    top_priority_needs: List[str] = Field(description="å‰ä¸‰å„ªå…ˆéœ€æ±‚çš„æ¨™é¡Œ")

class NeedEvaluator:
    def __init__(self, model: str = "gpt-4.1-mini", temperature: float = 0.3):
        """
        åˆå§‹åŒ–éœ€æ±‚è©•ä¼°å™¨
        
        Args:
            model: ä½¿ç”¨çš„ LLM æ¨¡å‹
            temperature: æ¨¡å‹å‰µé€ æ€§åƒæ•¸
        """
        self.llm = ChatOpenAI(model=model, temperature=temperature)
        self.parser = PydanticOutputParser(pydantic_object=NeedsEvaluationOutput)
    
    def evaluate_needs(self, needs: List[NeedItem]) -> NeedsEvaluationOutput:
        """
        è©•ä¼°éœ€æ±‚åˆ—è¡¨
        
        Args:
            needs: éœ€æ±‚é …ç›®åˆ—è¡¨
            
        Returns:
            NeedsEvaluationOutput: è©•ä¼°çµæœ
        """
        if not needs:
            return NeedsEvaluationOutput(
                evaluations=[],
                summary="æ²’æœ‰éœ€æ±‚é …ç›®éœ€è¦è©•ä¼°",
                top_priority_needs=[]
            )
        
        # æ§‹å»ºè©•ä¼° prompt
        evaluation_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é†«ç™‚å‰µæ–°é …ç›®è©•ä¼°å°ˆå®¶ï¼Œå…·å‚™è±å¯Œçš„é†«ç™‚æŠ€è¡“ã€å¸‚å ´åˆ†æå’Œé …ç›®ç®¡ç†ç¶“é©—ã€‚
            è«‹å°æä¾›çš„é†«ç™‚éœ€æ±‚é …ç›®é€²è¡Œå…¨é¢è©•ä¼°ã€‚
            
            è©•ä¼°ç¶­åº¦èªªæ˜ï¼š
            1. å¯è¡Œæ€§åˆ†æ•¸ (feasibility_score): è©•ä¼°æŠ€è¡“å¯¦ç¾çš„å¯èƒ½æ€§å’Œç¾å¯¦æ€§
            2. å½±éŸ¿åŠ›åˆ†æ•¸ (impact_score): è©•ä¼°å°é†«ç™‚ç³»çµ±å’Œæ‚£è€…çš„æ½›åœ¨å½±éŸ¿
            3. å‰µæ–°æ€§åˆ†æ•¸ (innovation_score): è©•ä¼°è§£æ±ºæ–¹æ¡ˆçš„å‰µæ–°ç¨‹åº¦å’Œå·®ç•°åŒ–
            4. è³‡æºéœ€æ±‚åˆ†æ•¸ (resource_score): è©•ä¼°æ‰€éœ€è³‡æºçš„åˆç†æ€§ (10åˆ†è¡¨ç¤ºè³‡æºéœ€æ±‚å¾ˆä½)
            5. ç¸½é«”åˆ†æ•¸ (overall_score): ç¶œåˆè€ƒæ…®æ‰€æœ‰å› ç´ çš„æ•´é«”è©•ä¼°
            
            è©•ä¼°åŸå‰‡ï¼š
            - æ‰€æœ‰åˆ†æ•¸ç¯„åœç‚º 0-10 åˆ†
            - è€ƒæ…®é†«ç™‚è¡Œæ¥­çš„ç‰¹æ®Šæ€§å’Œç›£ç®¡è¦æ±‚
            - é—œæ³¨å¯¦éš›å¯æ“ä½œæ€§å’Œå•†æ¥­åƒ¹å€¼
            - æä¾›å…·é«”ã€å¯è¡Œçš„æ”¹é€²å»ºè­°
            
            {format_instructions}
            """),
            ("human", """è«‹è©•ä¼°ä»¥ä¸‹é†«ç™‚éœ€æ±‚é …ç›®ï¼š

{needs_content}

è«‹ç‚ºæ¯å€‹éœ€æ±‚é …ç›®æä¾›è©³ç´°çš„è©•ä¼°ï¼ŒåŒ…æ‹¬å„ç¶­åº¦åˆ†æ•¸ã€å„ªåŠ£å‹¢åˆ†æå’Œæ”¹é€²å»ºè­°ã€‚
åŒæ™‚æä¾›æ•´é«”ç¸½çµå’Œå„ªå…ˆé †åºæ’åºã€‚""")
        ])
        
        # æ ¼å¼åŒ–éœ€æ±‚å…§å®¹
        needs_content = self._format_needs_for_evaluation(needs)
        
        # æ ¼å¼åŒ– prompt
        formatted_prompt = evaluation_prompt.partial(
            format_instructions=self.parser.get_format_instructions()
        )
        
        # åŸ·è¡Œè©•ä¼°
        chain = formatted_prompt | self.llm | self.parser
        
        try:
            result = chain.invoke({
                "needs_content": needs_content
            })
            return result
        except Exception as e:
            print(f"è©•ä¼°éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            # æä¾›é»˜èªè©•ä¼°çµæœ
            return self._create_default_evaluation(needs)
    
    def _format_needs_for_evaluation(self, needs: List[NeedItem]) -> str:
        """æ ¼å¼åŒ–éœ€æ±‚é …ç›®ç‚ºè©•ä¼°ç”¨çš„æ–‡æœ¬"""
        formatted_content = []
        for i, need in enumerate(needs, 1):
            content = f"""
éœ€æ±‚ {i}: {need['need']}
æ‘˜è¦: {need['summary']}
é†«ç™‚è§€é»: {need['medical_insights']}
æŠ€è¡“è§€é»: {need['tech_insights']}
å¯¦æ–½ç­–ç•¥: {need['strategy']}
---
"""
            formatted_content.append(content)
        
        return "\n".join(formatted_content)
    
    def _create_default_evaluation(self, needs: List[NeedItem]) -> NeedsEvaluationOutput:
        """å‰µå»ºé»˜èªè©•ä¼°çµæœï¼ˆç•¶è©•ä¼°å¤±æ•—æ™‚ä½¿ç”¨ï¼‰"""
        evaluations = []
        for need in needs:
            evaluation = NeedEvaluation(
                need_title=need.need,
                feasibility_score=5.0,
                impact_score=5.0,
                innovation_score=5.0,
                resource_score=5.0,
                overall_score=5.0,
                strengths=["éœ€è¦é€²ä¸€æ­¥åˆ†æ"],
                weaknesses=["è©•ä¼°éç¨‹å¤±æ•—"],
                recommendations=["é‡æ–°åŸ·è¡Œè©•ä¼°"]
            )
            evaluations.append(evaluation)
        
        return NeedsEvaluationOutput(
            evaluations=evaluations,
            summary="è©•ä¼°éç¨‹é‡åˆ°å•é¡Œï¼Œè«‹æª¢æŸ¥è¼¸å…¥æ•¸æ“šæˆ–é‡æ–°åŸ·è¡Œè©•ä¼°",
            top_priority_needs=[need.need for need in needs[:3]]
        )
    
    def print_evaluation_results(self, evaluation: NeedsEvaluationOutput):
        """ç¾åŒ–è¼¸å‡ºè©•ä¼°çµæœ"""
        print("\n" + "="*80)
        print("ğŸ¥ é†«ç™‚éœ€æ±‚é …ç›®è©•ä¼°å ±å‘Š")
        print("="*80)
        
        # è¼¸å‡ºæ¯å€‹éœ€æ±‚çš„è©•ä¼°
        for i, eval_result in enumerate(evaluation.evaluations, 1):
            print(f"\nğŸ“‹ éœ€æ±‚ {i}: {eval_result.need_title}")
            print("-" * 60)
            print(f"ğŸ“Š è©•ä¼°åˆ†æ•¸:")
            print(f"   â€¢ å¯è¡Œæ€§: {eval_result.feasibility_score:.1f}/10")
            print(f"   â€¢ å½±éŸ¿åŠ›: {eval_result.impact_score:.1f}/10")
            print(f"   â€¢ å‰µæ–°æ€§: {eval_result.innovation_score:.1f}/10")
            print(f"   â€¢ è³‡æºæ•ˆç‡: {eval_result.resource_score:.1f}/10")
            print(f"   â€¢ ç¸½é«”è©•åˆ†: {eval_result.overall_score:.1f}/10")
            
            print(f"\nâœ… å„ªå‹¢:")
            for strength in eval_result.strengths:
                print(f"   â€¢ {strength}")
            
            print(f"\nâš ï¸ åŠ£å‹¢:")
            for weakness in eval_result.weaknesses:
                print(f"   â€¢ {weakness}")
            
            print(f"\nğŸ’¡ æ”¹é€²å»ºè­°:")
            for recommendation in eval_result.recommendations:
                print(f"   â€¢ {recommendation}")
            print()
        
        # è¼¸å‡ºç¸½çµ
        print("="*80)
        print("ğŸ“ æ•´é«”è©•ä¼°ç¸½çµ")
        print("="*80)
        print(evaluation.summary)
        
        if evaluation.top_priority_needs:
            print(f"\nğŸ¯ å„ªå…ˆè™•ç†å»ºè­°:")
            for i, priority_need in enumerate(evaluation.top_priority_needs, 1):
                print(f"   {i}. {priority_need}")

# ä¾¿åˆ©å‡½æ•¸
def evaluate_needs_list(needs: List[NeedItem], verbose: bool = True) -> NeedsEvaluationOutput:
    """
    è©•ä¼°éœ€æ±‚åˆ—è¡¨çš„ä¾¿åˆ©å‡½æ•¸
    
    Args:
        needs: éœ€æ±‚é …ç›®åˆ—è¡¨
        verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°çµæœ
        
    Returns:
        è©•ä¼°çµæœ
    """
    evaluator = NeedEvaluator()
    result = evaluator.evaluate_needs(needs)
    
    if verbose:
        evaluator.print_evaluation_results(result)
    
    return result

# æ¸¬è©¦å‡½æ•¸
def test_evaluator():
    """æ¸¬è©¦è©•ä¼°å™¨åŠŸèƒ½"""
    # å‰µå»ºæ¸¬è©¦éœ€æ±‚
    test_needs = [
        NeedItem(
            need="æ™ºèƒ½ç—…åºŠç®¡ç†ç³»çµ±",
            summary="é–‹ç™¼æ™ºèƒ½ç—…åºŠåˆ†é…å’Œç›£æ§ç³»çµ±ï¼Œæé«˜ç—…åºŠä½¿ç”¨æ•ˆç‡",
            medical_insights="å¯ä»¥æ¸›å°‘ç—…æ‚£ç­‰å¾…æ™‚é–“ï¼Œæ”¹å–„é†«ç™‚å“è³ª",
            tech_insights="ä½¿ç”¨IoTæ„Ÿæ¸¬å™¨å’ŒAIç®—æ³•é€²è¡Œå³æ™‚ç›£æ§",
            strategy="åˆ†éšæ®µå¯¦æ–½ï¼Œå…ˆåœ¨æ€¥è¨ºç§‘è©¦é»"
        ),
        NeedItem(
            need="é ç¨‹é†«ç™‚è«®è©¢å¹³å°",
            summary="å»ºç«‹å®‰å…¨çš„é ç¨‹é†«ç™‚è«®è©¢ç³»çµ±",
            medical_insights="æ“´å¤§é†«ç™‚è¦†è“‹ç¯„åœï¼Œç‰¹åˆ¥æ˜¯åé åœ°å€",
            tech_insights="éœ€è¦é«˜å®‰å…¨æ€§çš„è¦–è¨Šé€šè©±å’Œé›»å­ç—…æ­·æ•´åˆ",
            strategy="èˆ‡ç¾æœ‰é†«é™¢ç³»çµ±æ•´åˆï¼Œç¢ºä¿æ•¸æ“šå®‰å…¨"
        )
    ]
    
    # åŸ·è¡Œè©•ä¼°
    result = evaluate_needs_list(test_needs)
    return result

if __name__ == "__main__":
    # åŸ·è¡Œæ¸¬è©¦
    test_result = test_evaluator()


